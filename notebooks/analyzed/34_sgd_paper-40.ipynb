{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-21T13:06:22.768652Z",
     "start_time": "2022-03-21T13:06:22.760122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10.0\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import hashlib\n",
    "import itertools\n",
    "import json\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "from math import comb\n",
    "from functools import reduce\n",
    "\n",
    "import bokeh\n",
    "import hiplot as hip\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_bokeh\n",
    "import ray\n",
    "from bson.objectid import ObjectId\n",
    "from matplotlib import pyplot as plt\n",
    "from omegaconf import OmegaConf\n",
    "from pymongo import MongoClient\n",
    "from math import comb\n",
    "from functools import reduce\n",
    "import seaborn as sns\n",
    "\n",
    "import xplogger\n",
    "\n",
    "print(xplogger.__version__)\n",
    "from xplogger.experiment_manager.record.record_list import RecordList\n",
    "from xplogger.experiment_manager.store.mongo import MongoStore\n",
    "from xplogger.experiment_manager.viz import bokeh as bokeh_viz\n",
    "from xplogger.experiment_manager.notebook import utils as notebook_utils\n",
    "from xplogger.parser.experiment import (\n",
    "    Experiment,\n",
    "    ExperimentSequence,\n",
    "    ExperimentSequenceDict,\n",
    ")\n",
    "from xplogger.parser.experiment import utils as experiment_utils\n",
    "\n",
    "sys.path.append(\"/private/home/sodhani/projects/abstraction_by_gating/\")\n",
    "\n",
    "from math import sqrt\n",
    "from time import time\n",
    "\n",
    "from IPython.display import JSON\n",
    "from notebooks import utils, ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-21T13:06:25.642211Z",
     "start_time": "2022-03-21T13:06:25.618033Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1002\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1002\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\": \"dM3QQsP+wXdHg42wTqW85BjZQdLNNIXqlPw/BgKoExPmTG7ZLML4EGqLMfqHT6ON\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\": \"8x57I4YuIfu8XyZfFo0XVr2WAT8EK4rh/uDe3wF7YuW2FNUSNEpJbsPaB1nJ2fz2\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\": \"3QTqdz9LyAm2i0sG5XTePsHec3UHWwVsrOL68SYRoAXsafvfAyqtQ+h440+qIBhS\"};\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\": \"dM3QQsP+wXdHg42wTqW85BjZQdLNNIXqlPw/BgKoExPmTG7ZLML4EGqLMfqHT6ON\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\": \"8x57I4YuIfu8XyZfFo0XVr2WAT8EK4rh/uDe3wF7YuW2FNUSNEpJbsPaB1nJ2fz2\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\": \"3QTqdz9LyAm2i0sG5XTePsHec3UHWwVsrOL68SYRoAXsafvfAyqtQ+h440+qIBhS\"};\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "pd.set_option(\"plotting.backend\", \"pandas_bokeh\")\n",
    "pandas_bokeh.output_notebook()\n",
    "\n",
    "%matplotlib inline\n",
    "# pd.set_option(\"plotting.backend\", \"pandas_bokeh\")\n",
    "# sns.set_style('darkgrid') # darkgrid, white grid, dark, white and ticks\n",
    "# pandas_bokeh.output_notebook()\n",
    "sns.color_palette(\"deep\")\n",
    "\n",
    "plt.rc('axes', titlesize=18)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=14)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=13)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=13)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=13)    # legend fontsize\n",
    "plt.rc('font', size=13)          # controls default text sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-21T13:06:25.904632Z",
     "start_time": "2022-03-21T13:06:25.900383Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0605 15:24:50.007082518 2245279 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0605 15:24:50.044627949 2245279 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0605 15:24:50.072722570 2245279 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '100.97.66.230',\n",
       " 'raylet_ip_address': '100.97.66.230',\n",
       " 'redis_address': '100.97.66.230:48595',\n",
       " 'object_store_address': '/tmp/ray/session_2022-06-05_15-24-48_843992_2245279/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2022-06-05_15-24-48_843992_2245279/sockets/raylet',\n",
       " 'webui_url': None,\n",
       " 'session_dir': '/tmp/ray/session_2022-06-05_15-24-48_843992_2245279',\n",
       " 'metrics_export_port': 58711,\n",
       " 'gcs_address': '100.97.66.230:37497',\n",
       " 'node_id': 'b9f83548274f3b87974de6422b50baab046024a380cf2f46ecd663e4'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_name = \"abstraction_by_gating\"\n",
    "\n",
    "use_record_ids = False\n",
    "ray.init(num_cpus=20, ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-21T13:06:26.379427Z",
     "start_time": "2022-03-21T13:06:26.214175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num documents: 43900\n"
     ]
    }
   ],
   "source": [
    "mongo_store = MongoStore(\n",
    "    config={\n",
    "        \"host\": \"localhost\",\n",
    "        \"port\": 27017,\n",
    "        \"db\": \"project\",\n",
    "        \"collection_name\": collection_name,\n",
    "    }\n",
    ")\n",
    "print(f\"Num documents: {mongo_store.collection.count_documents({})}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-21T13:06:32.885297Z",
     "start_time": "2022-03-21T13:06:27.209631Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.016807556152344\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "mongo_records = mongo_store.get_records(query={})\n",
    "print(time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-21T13:08:00.303133Z",
     "start_time": "2022-03-21T13:07:59.940036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.1736924648284912\n"
     ]
    }
   ],
   "source": [
    "mongo_to_record = {}\n",
    "issue_to_mongo_record = {}\n",
    "unanalyzed_records = []\n",
    "start = time()\n",
    "for record in mongo_records:\n",
    "    mongo_record_id = record.id\n",
    "    mongo_to_record[mongo_record_id] = record\n",
    "    issue_id = str(record[\"setup\"][\"git\"][\"issue_id\"])\n",
    "    if issue_id not in issue_to_mongo_record:\n",
    "        issue_to_mongo_record[issue_id] = []\n",
    "    issue_to_mongo_record[issue_id].append(record)\n",
    "    if record[\"status\"] != \"ANALYZED\":\n",
    "        unanalyzed_records.append(record)\n",
    "\n",
    "print(f\"Time taken: {time() - start}\")\n",
    "# assert len(unanalyzed_records) == len(mongo_store.get_unanalyzed_records())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-21T13:08:01.004077Z",
     "start_time": "2022-03-21T13:08:00.943053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unanalayzed records: 32475\n",
      "Counter({'1': 15942, '3': 4809, '25': 2751, '4': 2304, '36': 1408, '28': 1152, '29': 1123, '22': 962, '35': 614, '3-1': 480, '121': 372, 'dummy': 220, '31': 168, '18': 158, '30': 12})\n",
      "Time taken: 0.05469679832458496\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "record_list = RecordList(unanalyzed_records[:])\n",
    "print(f\"Total number of unanalayzed records: {len(record_list)}\")\n",
    "unique_issues = record_list.get_unique_issues()\n",
    "print(unique_issues)\n",
    "print(f\"Time taken: {time() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-21T13:08:03.347665Z",
     "start_time": "2022-03-21T13:08:03.311331Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'34'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2245279/3168882372.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrecord_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0missue_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"34\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mrecord_list\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0missue_to_mongo_record\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0missue_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '34'"
     ]
    }
   ],
   "source": [
    "record_list = []\n",
    "for issue_id in [\"34\"]:\n",
    "    record_list += issue_to_mongo_record[issue_id]\n",
    "\n",
    "\n",
    "def key_func(record):\n",
    "    return record[\"setup\"][\"id\"]\n",
    "\n",
    "def filter_fn(record):\n",
    "    return True\n",
    "\n",
    "print(len(record_list))\n",
    "record_list = RecordList([x for x in record_list if filter_fn(x)])\n",
    "slurm_id_to_record_map = record_list.map_to_slurm_id()\n",
    "record_list = record_list.get_unique(key_func).ray_make_oc_records()\n",
    "print(f\"Number of selected records: {len(record_list)}\")\n",
    "print(\n",
    "    f\"Number of uniques runs: {len(set(record['setup']['id'] for record in record_list))}\"\n",
    ")\n",
    "print(\n",
    "    f\"Number of unanalyzed runs: {len(set(record['setup']['id'] for record in record_list if record['status']!='ANALYZED'))}\"\n",
    ")\n",
    "print(\n",
    "    f\"Set of issues: {set(record['setup']['git']['issue_id'] for record in record_list)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Set of script ids: {set(record['setup']['script_id'] for record in record_list)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T21:23:53.926681Z",
     "start_time": "2022-03-19T21:23:53.923489Z"
    }
   },
   "outputs": [],
   "source": [
    "# record_list = RecordList(list(x for x in record_list if x.setup.script_id == \"dummy\"))\n",
    "print(len(record_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T21:25:16.813272Z",
     "start_time": "2022-03-19T21:23:55.391040Z"
    }
   },
   "outputs": [],
   "source": [
    "# record_list.delete(collection=mongo_store.collection, delete_from_filesystem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T21:04:37.719673Z",
     "start_time": "2022-03-19T21:04:36.831703Z"
    }
   },
   "outputs": [],
   "source": [
    "load_experiment_from_dir = lambda log_dir: utils.load_experiment_from_dir(\n",
    "    log_dir=log_dir,\n",
    "    cache_failed_experiment=True,\n",
    "    verbose=False,\n",
    "    skip_cache=False,\n",
    ")\n",
    "\n",
    "viz_params = record_list.get_viz_params()\n",
    "\n",
    "viz_params.remove(\"experiment\")\n",
    "start_time = time()\n",
    "# (\n",
    "#     exp_seq_dict,\n",
    "#     groups,\n",
    "#     hyperparams,\n",
    "# ) = record_list.ray_make_experiment_sequence_dict_groups_and_hyperparams(\n",
    "#     viz_params, load_experiment_from_dir\n",
    "# )\n",
    "\n",
    "(\n",
    "    exp_seq_dict,\n",
    "    groups,\n",
    "    hyperparams,\n",
    ") = record_list.make_experiment_sequence_dict_groups_and_hyperparams(\n",
    "    viz_params, load_experiment_from_dir\n",
    ")\n",
    "\n",
    "print(f\"Time taken: {time() - start_time}\")\n",
    "\n",
    "\n",
    "notebook_utils.prettyprint_dict(hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T21:04:37.729950Z",
     "start_time": "2022-03-19T21:04:37.725552Z"
    }
   },
   "outputs": [],
   "source": [
    "viz_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T21:04:37.808388Z",
     "start_time": "2022-03-19T21:04:37.731584Z"
    }
   },
   "outputs": [],
   "source": [
    "print(list(exp_seq_dict.values())[0])\n",
    "print(type(list(exp_seq_dict.values())[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T21:04:38.103885Z",
     "start_time": "2022-03-19T21:04:37.810266Z"
    }
   },
   "outputs": [],
   "source": [
    "exp = list(exp_seq_dict.values())[0][0]\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "exp.metrics[\"train_epoch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T21:04:38.112902Z",
     "start_time": "2022-03-19T21:04:38.105789Z"
    }
   },
   "outputs": [],
   "source": [
    "list(exp_seq_dict.values())[0][0].config[\"setup\"][\"viz\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T21:04:38.170434Z",
     "start_time": "2022-03-19T21:04:38.114725Z"
    }
   },
   "outputs": [],
   "source": [
    "notebook_utils.prettyprint_dict(hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T21:15:29.347053Z",
     "start_time": "2022-03-19T21:15:29.108389Z"
    }
   },
   "outputs": [],
   "source": [
    "# y_metric_list = [\"accuracy_odd_even\", \"accuracy_greater_than_four\"]\n",
    "y_metric_list = [\"average_accuracy_for_selected_paths\"]\n",
    "x_metric = \"epoch\"\n",
    "mode = \"test_epoch\"\n",
    "\n",
    "\n",
    "def filter_fn(key, experiment_sequence):\n",
    "    def filter_experiment(exp):\n",
    "        if not exp:\n",
    "            return False\n",
    "        model_cfg = exp.config[\"model\"]\n",
    "        return (\n",
    "            True\n",
    "            and exp.config[\"experiment\"][\"task\"][\"mode\"]\n",
    "            == \"permute_input_permute_target\"\n",
    "            and model_cfg[\"hidden_layer_cfg\"][\"dim\"] == 128\n",
    "            and model_cfg[\"num_layers\"] == 2\n",
    "            and model_cfg[\"weight_init\"][\"bias\"] == 0\n",
    "#             and model_cfg[\"weight_init\"][\"gain\"] in [0.1, 1.0, 10.0]\n",
    "            and exp.config[\"optimizer\"][\"_target_\"] == \"torch.optim.SGD\"\n",
    "            and exp.config[\"optimizer\"][\"lr\"] == 0.0001\n",
    "            and model_cfg[\"gate_cfg\"][\"mode\"] in [\"10_plus_mod_permute\"]\n",
    "            #             in [\"4_plus_mod\", \"4_plus_mod_permute\", \"6_plus_mod\", \"6_plus_mod_permute\"]\n",
    "            and exp.config[\"experiment\"][\"task\"][\"num_classes_in_selected_dataset\"]\n",
    "            == 10\n",
    "            and exp.config[\"model\"][\"hidden_layer_cfg\"][\"should_use_non_linearity\"]\n",
    "            == True\n",
    "            and exp.config[\"model\"][\"should_use_non_linearity\"] == True\n",
    "        )\n",
    "\n",
    "    return all(filter_experiment(exp) for exp in experiment_sequence)\n",
    "\n",
    "\n",
    "def get_function_to_get_experiment_name(param_list: list[DictConfig]):\n",
    "    unique_params_and_values = {}\n",
    "    words_to_ignore = []\n",
    "    for param in param_list:\n",
    "        for key, value in param.items():\n",
    "            if key not in unique_params_and_values:\n",
    "                unique_params_and_values[key] = set()\n",
    "            unique_params_and_values[key].add(value)\n",
    "    for key, value in unique_params_and_values.items():\n",
    "        if len(value) == 1:\n",
    "            words_to_ignore.append(key)\n",
    "\n",
    "    def get_experiment_name(params, **kwargs):\n",
    "        return \"-\".join(\n",
    "            [\n",
    "                f\"{val}\"\n",
    "                for key, val in sorted(\n",
    "                    list((OmegaConf.to_container(params)).items())\n",
    "                    + list(kwargs.items())\n",
    "                )\n",
    "                if all(word not in key for word in words_to_ignore)\n",
    "            ]\n",
    "        )\n",
    "        return \"-\".join(\n",
    "            [\n",
    "                f\"{val}\"\n",
    "                for key, val in sorted(\n",
    "                    list((OmegaConf.to_container(params)).items())\n",
    "                    + list(kwargs.items())\n",
    "                )\n",
    "                if all(word not in key for word in words_to_ignore)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    return get_experiment_name\n",
    "\n",
    "\n",
    "def plot(\n",
    "    filter_fn,\n",
    "    y_metric_list: list[str] = [\"return_mean\"],\n",
    "    x_metric: str = \"frames\",\n",
    "    mode: str = \"train\",\n",
    "    metadata_for_plot={},\n",
    "    p=None,\n",
    "    color_palette=None,\n",
    "    color_offset: int = 0,\n",
    "    colors=None,\n",
    "):\n",
    "\n",
    "    filtered_exp_seq_dict = ExperimentSequenceDict(\n",
    "        {\n",
    "            key: ExperimentSequence(experiment_sequence)\n",
    "            for key, experiment_sequence in sorted(\n",
    "                exp_seq_dict.items(),\n",
    "                key=lambda item: sorted(OmegaConf.to_container(item[0]).items()),\n",
    "            )\n",
    "            if filter_fn(key, experiment_sequence)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    fn_to_get_experiment_name = get_function_to_get_experiment_name(\n",
    "        param_list=list(filtered_exp_seq_dict.keys())\n",
    "    )\n",
    "\n",
    "    color_palette = bokeh.palettes.d3[\"Category20\"]\n",
    "\n",
    "    return bokeh_viz.plot_experiment_sequence_dict(\n",
    "        exp_seq_dict=filtered_exp_seq_dict,\n",
    "        kwargs_for_aggregate_metrics={\n",
    "            \"get_experiment_name\": fn_to_get_experiment_name,\n",
    "            \"x_name\": x_metric,\n",
    "            \"mode\": mode,\n",
    "            \"drop_duplicates\": True,\n",
    "            \"dropna\": True,\n",
    "            \"verbose\": True,\n",
    "            \"metric_names\": y_metric_list,\n",
    "            \"x_min\": 100,\n",
    "            \"x_max\": 1000,\n",
    "        },\n",
    "        metadata_for_plot=metadata_for_plot,\n",
    "        color_palette=color_palette,\n",
    "        p=p,\n",
    "        colors=colors,\n",
    "        color_offset=color_offset,\n",
    "    )\n",
    "\n",
    "\n",
    "title = \"title\"\n",
    "color_palette = bokeh.palettes.d3[\"Category20\"]\n",
    "colors = color_palette[20][::1]\n",
    "\n",
    "p = None\n",
    "\n",
    "p = plot(\n",
    "    filter_fn=filter_fn,\n",
    "    metadata_for_plot={\"title\": title, \"fill_alpha\": 0.2},\n",
    "    y_metric_list=y_metric_list,\n",
    "    x_metric=x_metric,\n",
    "    color_palette=color_palette,\n",
    "    mode=mode,\n",
    "    p=p,\n",
    "    color_offset=0,\n",
    "    colors=colors,\n",
    ")\n",
    "\n",
    "p.legend.click_policy = \"hide\"\n",
    "# p.legend.visible=\n",
    "\n",
    "\n",
    "bokeh.plotting.show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T21:15:34.628021Z",
     "start_time": "2022-03-19T21:15:34.624676Z"
    }
   },
   "outputs": [],
   "source": [
    "# # param_list = list(filtered_exp_seq_dict.keys())\n",
    "\n",
    "# x = np.asarray([0.1, 1.0, 10.0])\n",
    "\n",
    "# K = 10\n",
    "# #permute input\n",
    "# data_y = {\n",
    "#     10: {\n",
    "# #         \"trained\": np.asarray([91.4, 92.4, 88.1]),\n",
    "# #         \"untrained\": np.asarray([91.3, 65, 37.6]),\n",
    "# #         \"trained\": np.asarray([11.3, 92.4, 87.6]),\n",
    "# #         \"untrained\": np.asarray([11.3, 81.2, 43.8]),\n",
    "# #         \"trained\": np.asarray([11.3, 92.4, 87.7]),\n",
    "# #         \"untrained\": np.asarray([11.3, 84.1, 44.2]),\n",
    "# #         \"trained\": np.asarray([11.3, 97.3, 77.6]),\n",
    "# #         \"untrained\": np.asarray([11.3, 96.9, 55.7]),\n",
    "#         \"trained\": np.asarray([11.3, 97.1, 75.9]),\n",
    "#         \"untrained\": np.asarray([11.3, 95.2, 38.8]),\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# # rotate input\n",
    "# # data_y = {\n",
    "# #     10: {\n",
    "# #         \"trained\": np.asarray([91.2, 92.4, 88.1]),\n",
    "# #         \"untrained\": np.asarray([84.1, 70.3, 38.8]),\n",
    "# #     }\n",
    "# # }\n",
    "\n",
    "# for mode in [\"trained\", \"untrained\"]:\n",
    "#     plt.plot(x, (100 - data_y[K][mode]) / 100, label = f\"{mode} pathways\", marker = \"x\")\n",
    "    \n",
    "# plt.ylabel(\"error rate\")\n",
    "# plt.xscale('log')\n",
    "# plt.xlabel(\"gain ratio (initialization scale)\")\n",
    "\n",
    "# plt.title(f\"MNIST-Permuted-Input-Permuted-Output-40, K={K} Non-Linear\")\n",
    "# plt.grid()\n",
    "# plt.legend()\n",
    "\n",
    "# # plt.show()\n",
    "\n",
    "# # plt.savefig(\n",
    "# #     f\"/private/home/sodhani/projects/abstraction_by_gating/results/mnist-permute-input-40-gain-ratio-{K}-percent-128.pdf\",\n",
    "# #     dpi=300,\n",
    "# #     bbox_inches=\"tight\",\n",
    "# # )\n",
    "# # plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T21:15:35.012154Z",
     "start_time": "2022-03-19T21:15:35.008970Z"
    }
   },
   "outputs": [],
   "source": [
    "def map_combination_to_hyperparams(combination):\n",
    "    combination_dict = {}\n",
    "    for key, value in zip(hyperparams.keys(), combination):\n",
    "        combination_dict[key] = value\n",
    "    return combination_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T21:15:35.240121Z",
     "start_time": "2022-03-19T21:15:35.235799Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def make_metadata(\n",
    "    mode: str,\n",
    "    max_epochs: int,\n",
    "    min_epochs: int,\n",
    "    metric_name: str,\n",
    "):\n",
    "    metadata = OmegaConf.create(\n",
    "        {\n",
    "            \"metric_name\": metric_name,\n",
    "            \"mode\": mode,\n",
    "            \"x\": {\"name\": \"epoch\", \"min\": min_epochs, \"max\": max_epochs},\n",
    "        }\n",
    "    )\n",
    "\n",
    "    step_metadata = OmegaConf.create(\n",
    "        {\n",
    "            \"metric_name\": \"epoch\",\n",
    "            \"mode\": mode,\n",
    "            \"x\": {\"name\": \"epoch\", \"min\": min_epochs, \"max\": max_epochs},\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return metadata, step_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T21:15:35.485541Z",
     "start_time": "2022-03-19T21:15:35.483102Z"
    }
   },
   "outputs": [],
   "source": [
    "# list(exp_seq_dict.values())[0].aggregate_metrics(\n",
    "#         metric_names=[metadata.metric_name],\n",
    "#         x_name=metadata.x.name,\n",
    "#         x_min=metadata.x.min,\n",
    "#         x_max=metadata.x.max,\n",
    "#         mode=metadata.mode,\n",
    "#         drop_duplicates=True,\n",
    "#         verbose=True,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T21:15:35.748055Z",
     "start_time": "2022-03-19T21:15:35.742603Z"
    }
   },
   "outputs": [],
   "source": [
    "type(list(exp_seq_dict.values())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T21:15:38.310098Z",
     "start_time": "2022-03-19T21:15:35.992988Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "mode = \"test_epoch\"\n",
    "# metric_name = \"accuracy_task_two_encoder_task_one_decoder\"\n",
    "\n",
    "metrics = [\n",
    "    \"average_accuracy_for_selected_paths\",\n",
    "    \"average_accuracy_for_unselected_paths\",\n",
    "    \"average_loss_for_selected_paths\",\n",
    "    \"average_loss_for_unselected_paths\",\n",
    "]\n",
    "\n",
    "df_dict = {}\n",
    "\n",
    "for metric_name in metrics:\n",
    "    metadata, step_metadata = make_metadata(\n",
    "        mode=mode,\n",
    "        max_epochs=1000,\n",
    "        min_epochs=1,\n",
    "        metric_name=metric_name,\n",
    "    )\n",
    "\n",
    "    df_dict[metric_name] = notebook_utils.make_df(\n",
    "        metadata=metadata,\n",
    "        step_metadata=step_metadata,\n",
    "        groups=groups,\n",
    "        hyperparams=hyperparams,\n",
    "        exp_seq_dict=exp_seq_dict,\n",
    "    )\n",
    "    \n",
    "#     df_dict[key].drop(\n",
    "#         [],\n",
    "#         axis=1,\n",
    "#         inplace=True,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T21:15:38.351349Z",
     "start_time": "2022-03-19T21:15:38.312204Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dict[\"average_accuracy_for_unselected_paths\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T21:15:38.433052Z",
     "start_time": "2022-03-19T21:15:38.352974Z"
    }
   },
   "outputs": [],
   "source": [
    "keys_to_merge_on = [\n",
    "    \"model.hidden_layer_cfg.dim\",\n",
    "    \"experiment.task.num_classes_in_selected_dataset\",\n",
    "    \"experiment.num_epochs\",\n",
    "    \"dataloader.name\",\n",
    "    \"model.decoder_cfg.should_share\",\n",
    "    \"model.weight_init.bias\",\n",
    "    \"experiment.task.mode\",\n",
    "    \"model.num_layers\",\n",
    "    \"optimizer._target_\",\n",
    "    \"setup.script_id\",\n",
    "    \"model.weight_init.gain\",\n",
    "    \"model.weight_init.should_do\",\n",
    "    \"model.encoder_cfg.should_share\",\n",
    "    \"experiment.task.num_input_transformations\",\n",
    "    \"optimizer.lr\",\n",
    "    \"optimizer.momentum\",\n",
    "    \"model.should_use_non_linearity\",\n",
    "    \"model.gate_cfg.mode\",\n",
    "    \"dataloader.train_config.dataloader.batch_size\",\n",
    "    \"model.pretrained_cfg.should_use\",\n",
    "    \"model.hidden_layer_cfg.should_share\",\n",
    "    \"steps\",\n",
    "    \"seeds\",\n",
    "    \"model.hidden_layer_cfg.num_layers\",\n",
    "    \"model.hidden_layer_cfg.should_use_non_linearity\",\n",
    "    #     \"experiment.name\",\n",
    "    #     \"model.encoder_cfg.should_share\",\n",
    "    # #     \"experiment.name\",\n",
    "    #     \"model.weight_init.should_do\",\n",
    "    #     \"model.weight_init.gain\",\n",
    "    #     \"model.weight_init.bias\",\n",
    "    #     \"optimizer._target_\",\n",
    "    #     \"optimizer.lr\",\n",
    "    #     \"model.hidden_layer_cfg.dim\",\n",
    "    #     \"model.should_use_non_linearity\",\n",
    "    #     \"model.hidden_layer_cfg.should_share\",\n",
    "    #     \"model.num_layers\",\n",
    "    #\n",
    "    #     \"experiment.task.num_classes_in_selected_dataset\",\n",
    "    #     \"model.gate_cfg.mode\",\n",
    "    #     \"experiment.num_epochs\",\n",
    "    #     \"dataloader.train_config.dataloader.batch_size\",\n",
    "    #     \"optimizer.momentum\"\n",
    "]\n",
    "merged_df = df_dict[metrics[0]]\n",
    "for current_metric in metrics[1:]:\n",
    "    merged_df = merged_df.merge(\n",
    "        df_dict[current_metric], on=keys_to_merge_on, suffixes=[None, None]\n",
    "    )\n",
    "\n",
    "merged_df = merged_df.drop(\n",
    "    [\n",
    "        \"seeds\",\n",
    "        #         \"steps\",\n",
    "        #         \"experiment.name\",\n",
    "        #         \"experiment.task.num_classes_in_original_dataset\",\n",
    "        #         \"model.gate_cfg.mode\",\n",
    "        \"experiment.num_epochs\",\n",
    "        \"mean_average_loss_for_unselected_paths\",\n",
    "        \"mean_average_loss_for_selected_paths\",\n",
    "    ]\n",
    "    + [f\"stderr_{metric_name}\" for metric_name in metrics],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "merged_df.style.set_sticky(axis=\"columns\")\n",
    "\n",
    "merged_df\n",
    "\n",
    "# import seaborn as sns\n",
    "\n",
    "# cm = sns.light_palette(\"red\", as_cmap=True)\n",
    "\n",
    "# merged_df.style.background_gradient(\n",
    "#     axis=1, subset=[f\"mean_return_mean_{key}\" for key in keys], vmax=1.4, vmin=0.6\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T21:15:38.560234Z",
     "start_time": "2022-03-19T21:15:38.434978Z"
    }
   },
   "outputs": [],
   "source": [
    "df_to_plot = merged_df\n",
    "\n",
    "# keys_to_drop = [\"model.should_share_hidden_layer\", \"model.name\", \"model.should_share_decoder\", \n",
    "#                 \"stderr_accuracy_greater_than_four_encoder_odd_even_decoder\", \n",
    "#                 \"steps\", \"seeds\", \n",
    "#                 \"model.num_layers\", \"model.weight_init.should_do\", \n",
    "#                 \"model.should_share_encoder\", \"model.hidden_size\"\n",
    "#                ]\n",
    "# df_to_plot = df_to_plot.drop(keys_to_drop, axis=1)\n",
    "\n",
    "hip.Experiment.from_dataframe(df_to_plot).display()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T21:18:39.501153Z",
     "start_time": "2022-03-19T21:18:39.461623Z"
    }
   },
   "outputs": [],
   "source": [
    "df_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T21:20:32.576510Z",
     "start_time": "2022-03-19T21:20:32.307987Z"
    }
   },
   "outputs": [],
   "source": [
    "num_classes_in_selected_dataset = 10\n",
    "dim = 128\n",
    "optimizer_lr = 0.0001\n",
    "# experiment_task_mode = \"rotate_input_permute_target\"\n",
    "experiment_task_mode = \"permute_input_permute_target\"\n",
    "num_input_transformations = 40\n",
    "should_use_non_linearity = True\n",
    "\n",
    "\n",
    "def get_filters(df):\n",
    "    filters = {\n",
    "        \"experiment.task.num_classes_in_selected_dataset\": num_classes_in_selected_dataset,\n",
    "        \"experiment.task.mode\": experiment_task_mode,\n",
    "        \"optimizer.lr\": optimizer_lr,\n",
    "        \"model.hidden_layer_cfg.dim\": dim,\n",
    "        \"model.num_layers\": 2,\n",
    "        \"experiment.task.num_input_transformations\": num_input_transformations,\n",
    "        \"model.hidden_layer_cfg.should_use_non_linearity\": should_use_non_linearity,\n",
    "        \"model.should_use_non_linearity\": should_use_non_linearity,\n",
    "    }\n",
    "    \n",
    "    \n",
    "#     return (\n",
    "#             True\n",
    "#             and exp.config[\"optimizer\"][\"_target_\"] == \"torch.optim.SGD\"\n",
    "#             and exp.config[\"optimizer\"][\"lr\"] == 0.0001\n",
    "#             and model_cfg[\"gate_cfg\"][\"mode\"] in [\"10_plus_mod_permute\"]\n",
    "#             #             in [\"4_plus_mod\", \"4_plus_mod_permute\", \"6_plus_mod\", \"6_plus_mod_permute\"]\n",
    "#             and exp.config[\"experiment\"][\"task\"][\"num_classes_in_selected_dataset\"]\n",
    "#             == 10\n",
    "#             and exp.config[\"model\"][\"hidden_layer_cfg\"][\"should_use_non_linearity\"]\n",
    "#             == True\n",
    "#             and exp.config[\"model\"][\"should_use_non_linearity\"] == True\n",
    "#         )\n",
    "\n",
    "    return reduce(\n",
    "        lambda x, y: x & y, [df[key] == val for key, val in filters.items()], True\n",
    "    )\n",
    "\n",
    "\n",
    "df = df_to_plot[get_filters(df_to_plot)]\n",
    "\n",
    "x_metric_name = \"model.gate_cfg.mode\"\n",
    "# y_metric_name = \"mean_average_accuracy_for_selected_paths\"\n",
    "\n",
    "for y_metric_name in [\"mean_average_accuracy_for_selected_paths\", \"mean_average_accuracy_for_unselected_paths\"]:\n",
    "\n",
    "    points = []\n",
    "    for x, y in zip(df[x_metric_name], df[y_metric_name]):\n",
    "        x = ds.make_transformed_x(x)\n",
    "        points.append(ds.Point(x, y))\n",
    "\n",
    "    points.sort()\n",
    "\n",
    "    x_y = {}\n",
    "    # x, y = [], []\n",
    "    for p in points:\n",
    "        x = float(p.x.normalize(num_input_transformations=num_input_transformations))\n",
    "        if x not in x_y:\n",
    "            x_y[x] = y\n",
    "        else:\n",
    "            x_y[x] = max(x_y[x], p.y)\n",
    "\n",
    "    print(x_y)\n",
    "    # plt.plot(x, y)\n",
    "    if y_metric_name == \"mean_average_accuracy_for_unselected_paths\":\n",
    "        label = \"untrained pathways\"\n",
    "    else:\n",
    "        label = \"trained pathways\"\n",
    "    plt.plot(x_y.keys(), x_y.values(), label=label, marker = \"x\")\n",
    "    # print(x)\n",
    "    # print(y)\n",
    "\n",
    "if num_input_transformations == 100:\n",
    "    plt.title(r'MNIST-Permuted-Input-Permuted-Output-100')\n",
    "elif experiment_task_mode == \"rotate_input_permute_target\":\n",
    "    plt.title(r'MNIST-Rotated-Input-Permuted-Output-40-non-linear')\n",
    "elif experiment_task_mode == \"permute_input_permute_target\":\n",
    "    plt.title(r'MNIST-Permuted-Input-Permuted-Output-40-non-linear')\n",
    "    \n",
    "plt.xlabel(\"% of datasets used for training\")\n",
    "# plt.ylabel(\" \".join(y_metric_name.split(\"_\")[:3]))\n",
    "plt.ylabel(\"mean accuracy\")\n",
    "\n",
    "lower_range = 0.1\n",
    "upper_range = 0.99\n",
    "\n",
    "plt.yticks(np.arange(lower_range, upper_range, 0.1))\n",
    "plt.xticks(np.arange(10, 100, 10))\n",
    "plt.ylim([lower_range, upper_range])\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "path = f\"/private/home/sodhani/projects/abstraction_by_gating/results/mnist-{experiment_task_mode.replace('_', '-')}-{num_input_transformations}/line_{dim}.pdf\"\n",
    "# print(path)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# plt.savefig(\n",
    "# #     f\"/private/home/sodhani/projects/abstraction_by_gating/results/mnist-{experiment_task_mode.replace('_', '-')}-{num_input_transformations}/{y_metric_name}_{dim}.pdf\",\n",
    "#     path,\n",
    "#     dpi=300,\n",
    "#     bbox_inches=\"tight\",\n",
    "# )\n",
    "# plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T21:20:06.952026Z",
     "start_time": "2022-03-19T21:20:06.942640Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import math\n",
    "from typing import Any, Optional\n",
    "\n",
    "from bokeh.plotting import figure\n",
    "\n",
    "from xplogger.parser.experiment import ExperimentSequenceDict  # type: ignore\n",
    "\n",
    "\n",
    "# y_metric_list = [\"accuracy_odd_even\", \"accuracy_greater_than_four\"]\n",
    "y_metric_list = [\"average_accuracy_for_selected_paths\"]\n",
    "# y_metric_list = [\"accuracy\"]\n",
    "x_metric = \"epoch\"\n",
    "mode = \"test_epoch\"\n",
    "\n",
    "\n",
    "def filter_fn(key, experiment_sequence):\n",
    "    def filter_experiment(exp):\n",
    "        if not exp:\n",
    "            return False\n",
    "        model_cfg = exp.config[\"model\"]\n",
    "        return (\n",
    "            exp.config[\"experiment\"][\"task\"][\"mode\"] == \"permute_input_permute_target\"\n",
    "            and model_cfg[\"hidden_layer_cfg\"][\"dim\"] == 128\n",
    "            and model_cfg[\"num_layers\"] == 1\n",
    "            and model_cfg[\"weight_init\"][\"bias\"] == 0\n",
    "#             and model_cfg[\"weight_init\"][\"gain\"] not in [0.0001, 0.001, 0.01]\n",
    "            and exp.config[\"optimizer\"][\"_target_\"] == \"torch.optim.SGD\"\n",
    "            #             and model_cfg[\"weight_init\"][\"gain\"] == 0.001\n",
    "            #             and model_cfg[\"gate_cfg\"][\"mode\"] in [\"4_plus_mod_permute\", \"4_plus_mod\"]\n",
    "            and model_cfg[\"gate_cfg\"][\"mode\"]\n",
    "            in [\"90_plus_mod_permute\"]\n",
    "#             in [\"4_plus_mod\", \"4_plus_mod_permute\", \"6_plus_mod\", \"6_plus_mod_permute\"]\n",
    "            and exp.config[\"experiment\"][\"task\"][\"num_classes_in_selected_dataset\"] == 10\n",
    "        )\n",
    "\n",
    "    return all(filter_experiment(exp) for exp in experiment_sequence)\n",
    "\n",
    "\n",
    "def get_function_to_get_experiment_name(param_list: list[DictConfig]):\n",
    "    unique_params_and_values = {}\n",
    "    words_to_ignore = []\n",
    "    for param in param_list:\n",
    "        for key, value in param.items():\n",
    "            if key not in unique_params_and_values:\n",
    "                unique_params_and_values[key] = set()\n",
    "            unique_params_and_values[key].add(value)\n",
    "    for key, value in unique_params_and_values.items():\n",
    "        if len(value) == 1:\n",
    "            words_to_ignore.append(key)\n",
    "\n",
    "    def get_experiment_name(params, **kwargs):\n",
    "        return params[\"model.weight_init.gain\"]\n",
    "    return get_experiment_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T21:20:14.105727Z",
     "start_time": "2022-03-19T21:20:14.015588Z"
    },
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def matplotlib_plot_experiment_sequence_dict(\n",
    "    exp_seq_dict: ExperimentSequenceDict,\n",
    "    metadata_for_plot: dict[str, Any],\n",
    "    color_palette: list[Any],\n",
    "    plt: Optional[figure],\n",
    "    colors: Optional[list[str]] = None,\n",
    "    color_offset: int = 0,\n",
    "    return_all_metrics_with_same_length: bool = True,\n",
    "    kwargs_for_aggregate_metrics: Optional[dict[str, Any]] = None,\n",
    ") -> figure:\n",
    "    \"\"\"Plot the given experiment sequence dict as a matplotlib.\n",
    "\n",
    "    Args:\n",
    "        exp_seq_dict (ExperimentSequenceDict):\n",
    "        metadata_for_plot (dict[str, Any]):\n",
    "        color_palette (list[Any]):\n",
    "        p (Optional[figure]):\n",
    "        colors (Optional[list[str]], optional): Defaults to None.\n",
    "        color_offset (int, optional): Defaults to 0.\n",
    "        kwargs_for_aggregate_metrics (Optional[dict[str, Any]], optional):\n",
    "            These arguments are pass to aggregation function of exp_seq_dict.\n",
    "            Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        figure:\n",
    "    \"\"\"\n",
    "    if not kwargs_for_aggregate_metrics:\n",
    "        kwargs_for_aggregate_metrics = {}\n",
    "\n",
    "    for key in [\n",
    "        \"get_experiment_name\",\n",
    "        \"metric_names\",\n",
    "        \"x_name\",\n",
    "        \"x_min\",\n",
    "        \"x_max\",\n",
    "        \"mode\",\n",
    "        \"drop_duplicates\",\n",
    "        \"dropna\",\n",
    "        \"verbose\",\n",
    "    ]:\n",
    "        assert key in kwargs_for_aggregate_metrics\n",
    "\n",
    "    x_metric = kwargs_for_aggregate_metrics[\"x_name\"]\n",
    "    y_metric_list = kwargs_for_aggregate_metrics[\"metric_names\"]\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    data = exp_seq_dict.aggregate_metrics(\n",
    "        return_all_metrics_with_same_length=return_all_metrics_with_same_length,\n",
    "        **kwargs_for_aggregate_metrics,\n",
    "    )\n",
    "\n",
    "    if colors is None:\n",
    "        try:\n",
    "            colors = color_palette[len(data) + color_offset]\n",
    "        except KeyError:\n",
    "            # this could be because we have fewer data points than 3\n",
    "            colors = color_palette[3][: len(data) + color_offset]\n",
    "    assert colors is not None\n",
    "    for index, (key, y) in enumerate(data.items(), color_offset):\n",
    "        if key.endswith(f\"_{x_metric}\"):\n",
    "            continue\n",
    "        for current_metric_name in y_metric_list:\n",
    "            if key.endswith(current_metric_name):\n",
    "                current_exp_seq_key = key.replace(f\"_{current_metric_name}\", \"\")\n",
    "                break\n",
    "        else:\n",
    "            print(\"Can not find the metric name.\")\n",
    "            breakpoint()\n",
    "        x_key = f\"{current_exp_seq_key}_{x_metric}\"\n",
    "        x = data[x_key].mean(axis=0)[::20]\n",
    "        mean = y.mean(axis=0)[::20]\n",
    "        stderr = y.std(axis=0) / math.sqrt(len(y))\n",
    "        gain, mode = key.split(\"_\", 1)\n",
    "        if mode == \"average_accuracy_for_unselected_paths\":\n",
    "            marker = \"x\"\n",
    "            label = \"untrained\"\n",
    "        else:\n",
    "            marker = \".\"\n",
    "            label = \"trained\"\n",
    "        label = f\"{label}, gain={gain}\"\n",
    "        print(key, mode)\n",
    "        plt.plot(x, mean, linewidth=2, color=colors[index], label=label, marker=marker)\n",
    "        # p.varea(\n",
    "        #     x,\n",
    "        #     mean - stderr,\n",
    "        #     mean + stderr,\n",
    "        #     fill_alpha=metadata_for_plot.get(\"fill_alpha\", 0.6),\n",
    "        #     color=colors[index],\n",
    "        # )\n",
    "\n",
    "    # p.legend.location = \"bottom_right\"\n",
    "    # p.legend.click_policy = \"hide\"\n",
    "    # return p\n",
    "\n",
    "    \n",
    "def plot(\n",
    "    filter_fn,\n",
    "    y_metric_list: list[str] = [\"return_mean\"],\n",
    "    x_metric: str = \"frames\",\n",
    "    mode: str = \"train\",\n",
    "    metadata_for_plot={},\n",
    "    p=None,\n",
    "    color_palette=None,\n",
    "    color_offset: int = 0,\n",
    "    colors=None,\n",
    "):\n",
    "\n",
    "    filtered_exp_seq_dict = ExperimentSequenceDict(\n",
    "        {\n",
    "            key: ExperimentSequence(experiment_sequence)\n",
    "            for key, experiment_sequence in sorted(\n",
    "                exp_seq_dict.items(),\n",
    "                key=lambda item: sorted(OmegaConf.to_container(item[0]).items()),\n",
    "            )\n",
    "            if filter_fn(key, experiment_sequence)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    fn_to_get_experiment_name = get_function_to_get_experiment_name(\n",
    "        param_list=list(filtered_exp_seq_dict.keys())\n",
    "    )\n",
    "\n",
    "    color_palette = bokeh.palettes.d3[\"Category20\"]\n",
    "\n",
    "    return matplotlib_plot_experiment_sequence_dict(\n",
    "        exp_seq_dict=filtered_exp_seq_dict,\n",
    "        kwargs_for_aggregate_metrics = {\n",
    "            \"get_experiment_name\": fn_to_get_experiment_name,\n",
    "            \"x_name\": x_metric,\n",
    "            \"mode\": mode,\n",
    "            \"drop_duplicates\": True,\n",
    "            \"dropna\": True,\n",
    "            \"verbose\": True,\n",
    "            \"metric_names\": y_metric_list,\n",
    "            \"x_min\": 100,\n",
    "            \"x_max\": 1000,\n",
    "        },\n",
    "        metadata_for_plot=metadata_for_plot,\n",
    "        color_palette=color_palette,\n",
    "        plt = plt,\n",
    "#         p=p,\n",
    "        colors=colors,\n",
    "        color_offset=color_offset,\n",
    "    )\n",
    "        \n",
    "\n",
    "color_palette = bokeh.palettes.d3[\"Category20\"]\n",
    "colors = color_palette[20][::1]\n",
    "\n",
    "\n",
    "plot(\n",
    "    filter_fn=filter_fn,\n",
    "    metadata_for_plot={\"title\": title, \"fill_alpha\": 0.2},\n",
    "    y_metric_list=y_metric_list,\n",
    "    x_metric=x_metric,\n",
    "    color_palette=color_palette,\n",
    "    mode=mode,\n",
    "    p=p,\n",
    "    color_offset=0,\n",
    "    colors=colors,\n",
    ")\n",
    "\n",
    "plt.title(r'$10^{4}$ datasets')\n",
    "plt.ylabel(\"mean accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "\n",
    "# lower_range = 0.25\n",
    "# upper_range = 0.95\n",
    "\n",
    "# plt.yticks(np.arange(lower_range, upper_range, 0.1))\n",
    "# plt.xticks(np.arange(10, 100, 10))\n",
    "# plt.ylim([lower_range, upper_range])\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# plt.savefig(\n",
    "# #     f\"/private/home/sodhani/projects/abstraction_by_gating/results/mnist-{experiment_task_mode.replace('_', '-')}-{num_input_transformations}/{y_metric_name}_{dim}.pdf\",\n",
    "#     f\"/private/home/sodhani/projects/abstraction_by_gating/results/mnist-{experiment_task_mode.replace('_', '-')}-{num_input_transformations}/line_{dim}.pdf\",\n",
    "#     dpi=300,\n",
    "#     bbox_inches=\"tight\",\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abstraction_by_gating",
   "language": "python",
   "name": "abstraction_by_gating"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
